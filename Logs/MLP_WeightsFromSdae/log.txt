Log start, written by LogLib.StartUniqueLog at 2017-03-29___17-12-39-037514_pid_3780
MlpNet1 harnessStartTime=2017-03-29 17:12:39.037380
after setting randomSeed=37380
shape-trainCovariates=(55000, 784)
shape-trainLabels=(55000, 10)
shape-testImages=(10000, 784)
shape-testLabels=(10000, 10)
inputDim=784
outputDim=10
finalHiddenDim=64
hiddenDims=(256, 128, 64)
numHiddenLayers=3
totalDims=(784, 256, 128, 64, 10)
hiddenEncodeFuncName=relu
outputEncodeFuncName=linear
lossName=cross-entropy
learnRate=0.003
nTrainEpochs=10
printEpochFreq=1
batchSize 100 out of 55000
numBatchDatasets=550
bLoadWeights=True
loadWeightsFilename=[/media/sf_Python_Results/Tf_Results/2016-11-07/2016-11-07___17-34-05-529859/saveResultDict.p]
initWbTruncNormal=True
Before loading weights
sortedKeys-gLoadedWeights['bTiedWeights', 'decodeBiasesDict', 'decodeWeightsDict', 'encodeBiasesDict', 'encodeWeightsDict', 'hiddenDecodeFuncName', 'hiddenDims', 'hiddenEncodeFuncName', 'initDecodeBiasesDict', 'initDecodeWeightsDict', 'initEncodeBiasesDict', 'initEncodeWeightsDict', 'inputDim', 'lossName', 'totalDims']
changing from loadedWeights, newValue: hiddenEncodeFuncName=sigmoid
After loading weights
Before training MlpNet1
After initialising all variables
********************************************************************************
Start_PrintTrainableVariables
nodeIndex 0, node-name weights1:0, node-dtype <dtype: 'float32_ref'>
value: name weights1/read:0, dtype <dtype: 'float32'>, shape (784, 256)
nodeIndex 1, node-name weights2:0, node-dtype <dtype: 'float32_ref'>
value: name weights2/read:0, dtype <dtype: 'float32'>, shape (256, 128)
nodeIndex 2, node-name weights3:0, node-dtype <dtype: 'float32_ref'>
value: name weights3/read:0, dtype <dtype: 'float32'>, shape (128, 64)
nodeIndex 3, node-name weightsOut:0, node-dtype <dtype: 'float32_ref'>
value: name weightsOut/read:0, dtype <dtype: 'float32'>, shape (64, 10)
nodeIndex 4, node-name biases1:0, node-dtype <dtype: 'float32_ref'>
value: name biases1/read:0, dtype <dtype: 'float32'>, shape (256,)
nodeIndex 5, node-name biases2:0, node-dtype <dtype: 'float32_ref'>
value: name biases2/read:0, dtype <dtype: 'float32'>, shape (128,)
nodeIndex 6, node-name biases3:0, node-dtype <dtype: 'float32_ref'>
value: name biases3/read:0, dtype <dtype: 'float32'>, shape (64,)
nodeIndex 7, node-name biasesOut:0, node-dtype <dtype: 'float32_ref'>
value: name biasesOut/read:0, dtype <dtype: 'float32'>, shape (10,)
End_PrintTrainableVariables
********************************************************************************
Epoch 1, cost 0.6283304237879137
Epoch 2, cost 0.21018431349234165
Epoch 3, cost 0.13895028347996136
Epoch 4, cost 0.0976622490229255
Epoch 5, cost 0.07039207763631238
Epoch 6, cost 0.05008673858151514
Epoch 7, cost 0.03684018871831626
Epoch 8, cost 0.027053004528649827
Epoch 9, cost 0.02107572117651052
Epoch 10, cost 0.018150197817859315
After training
Accuracy: 0.9675
After training MlpNet1
saveResultDict-sortedSrdKeys['biasesDict', 'hiddenDims', 'hiddenEncodeFuncName', 'initBiasesDict', 'initWeightsDict', 'inputDim', 'lossName', 'outputDim', 'outputEncodeFuncName', 'totalDims', 'weightsDict']
After all training, initParams
numHiddenLayers=3
hLayerIndex=0
encodeWeightsThisLayer [0,0] -1.75152
encodeBiasesThisLayer [0] -1.4127
--------------------------------------------------------------------------------
shape-encodeWeightsThisLayer (784, 256)
shape-encodeBiasesThisLayer (256,)
--------------------------------------------------------------------------------
hLayerIndex=1
encodeWeightsThisLayer [0,0] 0.426662
encodeBiasesThisLayer [0] 1.46878
--------------------------------------------------------------------------------
shape-encodeWeightsThisLayer (256, 128)
shape-encodeBiasesThisLayer (128,)
--------------------------------------------------------------------------------
hLayerIndex=2
encodeWeightsThisLayer [0,0] -0.114404
encodeBiasesThisLayer [0] 1.58279
--------------------------------------------------------------------------------
shape-encodeWeightsThisLayer (128, 64)
shape-encodeBiasesThisLayer (64,)
--------------------------------------------------------------------------------
encodeWeightsOutLayer [0,0] -0.645946575169
encodeBiasesOutLayer [0] -1.06957702235
--------------------------------------------------------------------------------
shape-encodeWeightsOutLayer (64, 10)
shape-encodeBiasesOutLayer (10,)
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
After all training, finalParams
numHiddenLayers=3
hLayerIndex=0
encodeWeightsThisLayer [0,0] -1.75152
encodeBiasesThisLayer [0] -1.22006
--------------------------------------------------------------------------------
shape-encodeWeightsThisLayer (784, 256)
shape-encodeBiasesThisLayer (256,)
--------------------------------------------------------------------------------
hLayerIndex=1
encodeWeightsThisLayer [0,0] 0.5369
encodeBiasesThisLayer [0] 1.53192
--------------------------------------------------------------------------------
shape-encodeWeightsThisLayer (256, 128)
shape-encodeBiasesThisLayer (128,)
--------------------------------------------------------------------------------
hLayerIndex=2
encodeWeightsThisLayer [0,0] 0.222672
encodeBiasesThisLayer [0] 1.71601
--------------------------------------------------------------------------------
shape-encodeWeightsThisLayer (128, 64)
shape-encodeBiasesThisLayer (64,)
--------------------------------------------------------------------------------
encodeWeightsOutLayer [0,0] -1.1696
encodeBiasesOutLayer [0] -1.0111
--------------------------------------------------------------------------------
shape-encodeWeightsOutLayer (64, 10)
shape-encodeBiasesOutLayer (10,)
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
After saving saveResultDict to file
MlpNet1 harnessDuration 0:01:01.074305
MlpNet1 duration as str 1.0m 1.074305s
